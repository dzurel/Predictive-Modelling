{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Data and Predictive Pipelines\n",
    "#### Making Meaningful Predictions from Data\n",
    "\n",
    "In this notebook, I will go over basic training, testing, and validating data and move on to some pipeline practice. I will be looking at how well various words can predict a business' rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Training, Validating, Testing\n",
    "1. **Training datasets** form the basis of a model's learning, teaching it how to estimate its output.\n",
    "2. **Validation datasets** check the accuracy, quality, and integrity of a model, as well as fine-tuning any parameters that are not directly optimized.\n",
    "3. **Test datasets** are usually what I am most interested in -- how does the model perform with previously unseen data that reflects real-world cases?\n",
    "\n",
    "To learn more about the difference between these, click here: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n",
    "\n",
    "A good model is one that generalizes to new data! If a model performs well on a training set but not on new data, then it is probably **overfitting** the training data.\n",
    "\n",
    "#### \"Theorems\" about these sets\n",
    "\n",
    "* The training error increases as lambda increases\n",
    "* The validation and test error are at least as large as the training error (assuming infinitely large random partitions)\n",
    "* The validation/test error will usually have a “sweet spot” between under- and over-fitting\n",
    "\n",
    "### The Data\n",
    "\n",
    "This dataset contains 25,000 Yelp reviews of various businesses. \n",
    "\n",
    "### Reading the Data\n",
    "First I import a few libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import string # Some string utilities\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer # Stemming\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/reviews.json\"\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "# Load in JSON file\n",
    "dataset = []\n",
    "for i in range(25000):\n",
    "    dataset.append(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'QScdf32LViCASQirYGJ6hA',\n",
       " 'user_id': 'ZnZmF11O42qfhhNNA5juhA',\n",
       " 'business_id': 'XHYxwXtnidQsm89rE_OIUQ',\n",
       " 'stars': 5.0,\n",
       " 'useful': 0,\n",
       " 'funny': 0,\n",
       " 'cool': 0,\n",
       " 'text': \"WOW!! This company is amazing!!!!! As a full time working mom I can't tell you how hard it is to keep up with keeping the house clean. I am a neat freak and they came in and made my house so spotless. It is such a breath of fresh air coming home and knowing I don't have to worry about anything! My house is so shiny and it even smelled good! You guys did a fantastic job and we will definitely be contacting you again! This cleaning came at the perfect time and the cleaning ladies were so nice and friendly! Thank you so much! You have made a life long customer!\",\n",
       " 'date': '2016-11-22 01:48:06'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first entry in dataset\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Examine The Dataset\n",
    "#### Counting Number of Unique Words\n",
    "Before I start analyzing this data, let's see how many unique words we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119350\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words\n",
    "wordCount = defaultdict(int)\n",
    "for d in dataset:\n",
    "    for w in d['text'].split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of words! This number of words is too many to deal with (i.e., it would result in a 119,350 dimensional feature vector if used naively). Let's try to reduce this by removing punctuation and capitalization, so that two instances of the same word will be counted as being the same even if punctuated or capitalized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52202\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still left with a large number of words, so possibly we can reduce this number of words further if we treat different word inflections (e.g. \"drinks\" vs. \"drinking\") as being instances of the same word, by identifying their word stem (i.e., \"drink\"). This process is called \"stemming\".\n",
    "I perform stemming using a stemmer from the NLTK (Natural Language Toolkit) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39547\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization and using stemming.\n",
    "# This one might take a bit of time to run -- be patient!\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer() # object doing the stemming\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w) # with stemming\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and Building Features from the Most Common Words\n",
    "That's still a lot of words. One way to deal with this is to take the most common words and build features out of those.\n",
    "\n",
    "First I build a few data structures to count the number of instances of each word. Here I remove punctuation and capitalization, but do not apply stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having counted the number of instances of each word, I can sort them to find the most common, and build a word index based on these frequencies. For example, the most frequent word will have index 0, the secont most frequent will have index 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse() # Most frequent = index 0\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our Bag-of-Words Feature Representation\n",
    "Now that I have our dictionary of common words, we can now build a feature vector by counting how often each of these words appears in each review. This is called a **\"bag-of-words\" feature representation**. This results in a 1,000 dimensional feature vector (1,001 if we include an offset term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building bag-of-words\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Build Training Dataset\n",
    "I will build our training set by doing the following:\n",
    "1. Shuffle entries\n",
    "2. Define `X` - matrix of features\n",
    "3. Define `y` - the outcomes\n",
    "4. Perform least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset] # using the bag-of-words function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['stars'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y,rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Visualize Important Words\n",
    "Once the model has finished training, I can examine which are the most positive (or negative) words by looking at the largest (or smallest) corresponding values for theta To do so, let's sort the words based on their corresponding weights from `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordWeights = list(zip(theta, words + ['offset']))\n",
    "wordWeights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.7553245155694435, 'worst'),\n",
       " (-0.7389947690061027, 'horrible'),\n",
       " (-0.6005449383926107, 'terrible'),\n",
       " (-0.5290251025492264, 'rude'),\n",
       " (-0.5215853670104232, 'poor'),\n",
       " (-0.48335065677885247, 'bland'),\n",
       " (-0.48050793069310804, 'awful'),\n",
       " (-0.4623144737888688, 'overpriced'),\n",
       " (-0.46124438293703945, 'disappointing'),\n",
       " (-0.320489881944537, 'dirty')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most negative words\n",
    "wordWeights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2507418090182752, 'best'),\n",
       " (0.2710529489617402, 'reasonable'),\n",
       " (0.27383412028756937, 'above'),\n",
       " (0.27552216151668696, 'professional'),\n",
       " (0.3063027581586295, 'awesome'),\n",
       " (0.3110107093777941, 'amazing'),\n",
       " (0.3135436872881369, 'excellent'),\n",
       " (0.3153643923320769, 'pleased'),\n",
       " (0.3190050881565601, 'outstanding'),\n",
       " (3.6422465896845466, 'offset')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 most positive words (10th is offset term)\n",
    "wordWeights[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Include Regularizer\n",
    "**Regularization** is the process of penalizing model complexity during training. In this case, though the above model was effective, it was also very high dimensional, and thus may have been prone to **overfitting**. We can try to address this by adding a regularizer to our model.\n",
    "\n",
    "The \"Ridge\" class from `sklearn` implements a least squares regression model (as in our example above) that includes a regularizer. The strength of the regularizer is controlled by the parameter `alpha` (equivalent to `lambda` in the course lectures). Otherwise, fitting the ridge regression model is exactly the same as fitting a regular least squares model! \n",
    "\n",
    "Here is the method call I am using: `model = linear_model.Ridge(1.0, fit_intercept=False)`\n",
    "\n",
    "**Note the two extra parameters:** The first is the regularization strength (`alpha`). The second indicates I do not want the model to fit an intercept (since the feature vector already includes one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Ridge in module sklearn.linear_model._ridge:\n",
      "\n",
      "class Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, _BaseRidge)\n",
      " |  Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)\n",
      " |  \n",
      " |  Linear least squares with l2 regularization.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |  ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      " |  \n",
      " |  This model solves a regression model where the loss function is\n",
      " |  the linear least squares function and regularization is given by\n",
      " |  the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      " |  This estimator has built-in support for multi-variate regression\n",
      " |  (i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : {float, array-like of shape (n_targets,)}, default=1.0\n",
      " |      Regularization strength; must be a positive float. Regularization\n",
      " |      improves the conditioning of the problem and reduces the variance of\n",
      " |      the estimates. Larger values specify stronger regularization.\n",
      " |      Alpha corresponds to ``C^-1`` in other linear models such as\n",
      " |      LogisticRegression or LinearSVC. If an array is passed, penalties are\n",
      " |      assumed to be specific to the targets. Hence they must correspond in\n",
      " |      number.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, optional\n",
      " |      Maximum number of iterations for conjugate gradient solver.\n",
      " |      For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      " |      by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Precision of the solution.\n",
      " |  \n",
      " |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'}\n",
      " |      Solver to use in the computational routines:\n",
      " |  \n",
      " |      - 'auto' chooses the solver automatically based on the type of data.\n",
      " |  \n",
      " |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      " |        coefficients. More stable for singular matrices than\n",
      " |        'cholesky'.\n",
      " |  \n",
      " |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      " |        obtain a closed-form solution.\n",
      " |  \n",
      " |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      " |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      " |        more appropriate than 'cholesky' for large-scale data\n",
      " |        (possibility to set `tol` and `max_iter`).\n",
      " |  \n",
      " |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      " |        scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      " |        procedure.\n",
      " |  \n",
      " |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      " |        its improved, unbiased version named SAGA. Both methods also use an\n",
      " |        iterative procedure, and are often faster than other solvers when\n",
      " |        both n_samples and n_features are large. Note that 'sag' and\n",
      " |        'saga' fast convergence is only guaranteed on features with\n",
      " |        approximately the same scale. You can preprocess the data with a\n",
      " |        scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      All last five solvers support both dense and sparse data. However, only\n",
      " |      'sparse_cg' supports sparse input when `fit_intercept` is True.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag'.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *random_state* to support Stochastic Average Gradient.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features,) or (n_targets, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : float or array of shape (n_targets,)\n",
      " |      Independent term in decision function. Set to 0.0 if\n",
      " |      ``fit_intercept = False``.\n",
      " |  \n",
      " |  n_iter_ : None or array of shape (n_targets,)\n",
      " |      Actual number of iterations for each target. Available only for\n",
      " |      sag and lsqr solvers. Other solvers will return None.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RidgeClassifier : Ridge classifier\n",
      " |  RidgeCV : Ridge regression with built-in cross validation\n",
      " |  :class:`sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      " |      combines ridge regression with the kernel trick\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import Ridge\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> clf = Ridge(alpha=1.0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Ridge()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Ridge\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      _BaseRidge\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Ridge regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values\n",
      " |      \n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample. If given a float, every sample\n",
      " |          will have the same weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with :func:`~sklearn.metrics.r2_score`. This will influence the\n",
      " |      ``score`` method of all the multioutput regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`). To specify the\n",
      " |      default value manually and avoid the warning, please either call\n",
      " |      :func:`~sklearn.metrics.r2_score` directly or make a custom scorer with\n",
      " |      :func:`~sklearn.metrics.make_scorer` (the built-in scorer ``'r2'`` uses\n",
      " |      ``multioutput='uniform_average'``).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linear_model.Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the coefficients learned by our new regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordWeights = list(zip(theta, words + ['offset']))\n",
    "wordWeights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.7542478890211676, 'worst'),\n",
       " (-0.7380238948354739, 'horrible'),\n",
       " (-0.5997972082231678, 'terrible'),\n",
       " (-0.528644144203692, 'rude'),\n",
       " (-0.5206526415791057, 'poor'),\n",
       " (-0.48254221668243685, 'bland'),\n",
       " (-0.4793726507312775, 'awful'),\n",
       " (-0.4608536828058321, 'overpriced'),\n",
       " (-0.459806274640262, 'disappointing'),\n",
       " (-0.3197940121855978, 'dirty')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most negative words\n",
    "wordWeights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25089466451190345, 'best'),\n",
       " (0.2707656635951766, 'reasonable'),\n",
       " (0.27319251332630284, 'above'),\n",
       " (0.27536923153242904, 'professional'),\n",
       " (0.30631213715059025, 'awesome'),\n",
       " (0.31111856323805875, 'amazing'),\n",
       " (0.3135411208752763, 'excellent'),\n",
       " (0.3142912016174824, 'pleased'),\n",
       " (0.31821406027182847, 'outstanding'),\n",
       " (3.6416051508951472, 'offset')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 most positive words (10th is offset term)\n",
    "wordWeights[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Regression Diagnostics: MSE and R^2 Review\n",
    "Let's step away from programming for a moment. How do we evaluate our regressors? \n",
    "\n",
    "### 2a. MSE (Mean Squared Error)\n",
    "What is the MSE (which we have already been using) and its relationship to the R^2 statistic? I start by extracting the predictions from the model and computing their squared differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [(x-y)**2 for (x,y) in zip(predictions,y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **MSE** is just the average (mean) of these squared differences, which we can compute with a few trivial Python commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9237226689725614\n"
     ]
    }
   ],
   "source": [
    "MSE = sum(differences) / len(differences)\n",
    "print(\"MSE = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. R^2\n",
    "the **R^2** (and the **FVU**, or \"Fraction of Variance Unexplained\") normalize the **Mean Squared Error** based on the variance of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.5582919710243408\n"
     ]
    }
   ],
   "source": [
    "FVU = MSE / numpy.var(y)\n",
    "R2 = 1 - FVU\n",
    "print(\"R2 = \" + str(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Predictive Pipelines\n",
    "\n",
    "In its most basic form, a pipeline links steps together. In machine learning and data science, pipelines allow you transform data from one representation to another through a series of steps. \n",
    "\n",
    "A lower-level example can be found in Unix, where you can *pipeline* the *output* of some command as an *input* some other command with the `|` (e.g. `cat words.txt | wc -c` will result in the number of characters in `words.txt`). In this notebook, I will implement a regularization pipeline to help us train, test, and validate data, where (as stated before) **regularization** is the process of penalizing model complexity during training.\n",
    "\n",
    "Let's import libraries and read our dataset in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/reviews.json\"\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "# Load in JSON file\n",
    "dataset = []\n",
    "for i in range(25000):\n",
    "    dataset.append(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Rebuild Common Word Features\n",
    "This is identical to what we did in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "for d in dataset:\n",
    "  r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse() # Highest frequency = index 0\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words function\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Build the Validation Set\n",
    "Again I split our data, but this time I split it into _three_ parts - a training, a validation, and a test component. Recall that validation sets check the accuracy, quality, and integrity of a model, as well as fine-tuning any parameters that are not directly optimized.\n",
    "\n",
    "Let's shuffle the dataset and define `X` and `y` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)\n",
    "X = [feature(d) for d in dataset]\n",
    "y = [d['stars'] for d in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll use half of our data (and labels) for **training**, the next quarter for **validation**, and the final quarter for **testing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "\n",
    "X_train = X[:N//2]\n",
    "X_valid = X[N//2:3*N//4]\n",
    "X_test = X[3*N//4:]\n",
    "\n",
    "y_train = y[:N//2]\n",
    "y_valid = y[N//2:3*N//4]\n",
    "y_test = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 12500, 6250, 6250)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine size of data\n",
    "len(X), len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Train the Model\n",
    "Again I'll train a model based on regularized (Ridge) regression. My MSE function is the same as before, but this time for convience takes an (already trained) model as an input parameter.\n",
    "\n",
    "#### Finally, to implement the pipeline, I:\n",
    "1. Iterate through various values of lambda\n",
    "2. Fit a ridge regression model for each of these values\n",
    "3. Evaluate the performance of this model on the validation set\n",
    "4. Keep track of which model is the best we've seen so far (on the validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find Mean Squared Error\n",
    "def MSE(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    differences = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to keep track of the current best model and MSE\n",
    "bestModel = None \n",
    "bestMSE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.01, training/validation error = 0.8750598201114304/1.0432668230964726\n",
      "lambda = 0.1, training/validation error = 0.8750598593116713/1.0431903936265863\n",
      "lambda = 1, training/validation error = 0.8750637401231084/1.0424352096193081\n",
      "lambda = 10, training/validation error = 0.8754164032180508/1.0357125897260049\n",
      "lambda = 100, training/validation error = 0.8935572875821944/1.0107344692176796\n"
     ]
    }
   ],
   "source": [
    "# Train and fine-tune model with training and validation sets\n",
    "for lamb in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = linear_model.Ridge(lamb, fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    mseTrain = MSE(model, X_train, y_train)\n",
    "    mseValid = MSE(model, X_valid, y_valid)\n",
    "    \n",
    "    print(\"lambda = \" + str(lamb) + \", training/validation error = \" +\n",
    "          str(mseTrain) + '/' + str(mseValid))\n",
    "    if not bestModel or mseValid < bestMSE:\n",
    "        bestModel = model\n",
    "        bestMSE = mseValid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I evaluate the performance of my best model on the **test** set. Note that this is the only time throughout the entire pipeline that I examine the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error = 1.0723185592283093\n"
     ]
    }
   ],
   "source": [
    "mseTest = MSE(bestModel, X_test, y_test)\n",
    "print(\"test error = \" + str(mseTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
